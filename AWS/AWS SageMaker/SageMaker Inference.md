# SageMaker Inference

Options:

* [Real-Time inference](https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints.html)
* [Batch Transform](https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html)
* [Asynchronous Inference](https://docs.aws.amazon.com/sagemaker/latest/dg/async-inference.html)
* [Serverless Inference](https://docs.aws.amazon.com/sagemaker/latest/dg/serverless-endpoints.html)

Docs:

* [Large model inference tutorials](https://docs.aws.amazon.com/sagemaker/latest/dg/large-model-inference-tutorials.html)

Articles:

* [An Amazon SageMaker Inference comparison with Hugging Face Transformers](https://www.philschmid.de/sagemaker-inference-comparison)
* [Deploy Llama 2 7B/13B/70B on Amazon SageMaker](https://www.philschmid.de/sagemaker-llama-llm)
* [How to deploy Llama2 on AWS and Huggingface with Python](https://www.rootstrap.com/blog/how-to-deploy-llama2-on-aws-and-huggingface-with-python)
* [Improve throughput performance of Llama 2 models using Amazon SageMaker](https://aws.amazon.com/blogs/machine-learning/improve-throughput-performance-of-llama-2-models-using-amazon-sagemaker/)

Samples:

* [Deploying a Multi-Model and Multi-RAG Powered Chatbot Using AWS CDK on AWS](https://github.com/aws-samples/aws-genai-llm-chatbot)

# Real-Time inference

* [Docs](https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints.html)

# Batch Transform

* [Docs](https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html)
* [SageMaker Autopilot Batch Inferencing](https://docs.aws.amazon.com/sagemaker/latest/dg/autopilot-deploy-models-batch.html)

# Asynchronous Inference

* [Docs](https://docs.aws.amazon.com/sagemaker/latest/dg/async-inference.html)

# Serverless Inference

* [Docs](https://docs.aws.amazon.com/sagemaker/latest/dg/serverless-endpoints.html)
