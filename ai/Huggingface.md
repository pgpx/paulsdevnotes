# Huggingface

## Huggingface Hub

* [Docs](https://huggingface.co/docs/hub/index)

### SDK

* [Cache](https://huggingface.co/docs/huggingface_hub/guides/manage-cache)
* [Text Generation Inference (TGI)](https://huggingface.co/docs/text-generation-inference/index)  is a toolkit for deploying and serving Large Language Models (LLMs)
### Python Library

* [GitHub](https://github.com/huggingface/huggingface_hub)
* [Docs](https://huggingface.co/docs/huggingface_hub/index)

## Tutorials

* [Generation with LLMs](https://huggingface.co/docs/transformers/llm_tutorial)
* [Handling big models for inference](https://huggingface.co/docs/accelerate/v0.22.0/en/concept_guides/big_model_inference)