# * Falcon

* [tiiuae/falcon-180B-chat](https://huggingface.co/tiiuae/falcon-180B-chat)
    * <https://huggingface.co/blog/falcon>
    * [Falcon 180B foundation model from TII is now available via Amazon SageMaker JumpStart](https://aws.amazon.com/blogs/machine-learning/falcon-180b-foundation-model-from-tii-is-now-available-via-amazon-sagemaker-jumpstart/) - needs `ml.p4de.24xlarge` instances - 8-bit quantized can run on `ml.p4d.24xlarge` but inference is 5x slower.
* [Deploy Falcon 180B on Amazon SageMaker](https://www.philschmid.de/sagemaker-falcon-180b)
  * <https://github.com/philschmid/sagemaker-falcon-180b-samples>
* [Fine-tune Falcon 180B with QLoRA and Flash Attention on Amazon SageMaker](https://www.philschmid.de/sagemaker-falcon-180b-qlora)
* [Serving Falcon models with ðŸ¤— Text Generation Inference (TGI)](https://vilsonrodrigues.medium.com/serving-falcon-models-with-text-generation-inference-tgi-5f32005c663b)
* [Falcon 180B foundation model from TII is now available via Amazon SageMaker JumpStart](https://aws.amazon.com/blogs/machine-learning/falcon-180b-foundation-model-from-tii-is-now-available-via-amazon-sagemaker-jumpstart/)
* [Hello world to Falcon 180B](https://billtcheng2013.medium.com/hello-world-to-falcon-180b-25b257700a6a) -
  4bit quantization and Multi-GPU
* [Improve performance of Falcon models with Amazon SageMaker](https://aws.amazon.com/blogs/machine-learning/improve-performance-of-falcon-models-with-amazon-sagemaker/)