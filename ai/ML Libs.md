# ML Libs

* [infinity](https://github.com/michaelfeil/infinity) is a high-throughput, low-latency REST API for serving vector embeddings, supporting a wide range of sentence-transformer models and frameworks.
* [NVIDIA NeMo ](https://github.com/NVIDIA/NeMo) is a conversational AI toolkit.
* [NVIDIA TensorRT-LLM](https://github.com/NVIDIA/TensorRT-LLM/) - provides users with an easy-to-use Python API to define Large Language Models (LLMs) and build TensorRT engines that contain state-of-the-art optimizations to perform inference efficiently on NVIDIA GPUs.
* [Optimum-NVIDIA](https://github.com/huggingface/optimum-nvidia/) ([PyPi](https://pypi.org/project/optimum/)) delivers the best inference performance on the NVIDIA platform through Hugging Face.]
* [Ray](https://www.ray.io/)  is an open-source unified compute framework that makes it easy to scale AI and Python workloads
* [Hugging Face](https://huggingface.co/docs)
  * [Datasets](https://huggingface.co/docs/datasets/index) is a library for easily accessing and sharing datasets for Audio, Computer Vision, and Natural Language Processing (NLP) tasks.
  * [Transformers](https://huggingface.co/docs/transformers/index)
* [FlashAttention](https://github.com/Dao-AILab/flash-attention)